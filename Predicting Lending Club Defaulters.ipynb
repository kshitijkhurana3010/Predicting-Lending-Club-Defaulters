{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lending_club_data():\n",
    "    raw_data = pd.read_csv(\"LendingClub2012to2013.csv\", low_memory = False, skiprows=[0])\n",
    "    return(raw_data)\n",
    "    \n",
    "def data_clean(raw_data):\n",
    "    no_incomplete_rows = raw_data[raw_data['loan_status'].isin(['Fully Paid', 'Charged Off', 'Default'])]\n",
    "    no_incomplete_rows['loan_status'] = no_incomplete_rows['loan_status'].apply(lambda x: 0 if x == \"Fully Paid\" else 1)\n",
    "    leakage_to_drop = ['issue_d', 'recoveries', 'collection_recovery_fee', 'last_fico_range_high', 'last_fico_range_low', 'last_credit_pull_d', 'total_rec_prncp', 'last_pymnt_amnt', 'total_pymnt', 'total_pymnt_inv', 'last_pymnt_d', 'total_rec_late_fee', 'total_rec_int', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'out_prncp', 'out_prncp_inv', 'pymnt_plan', 'next_pymnt_d']\n",
    "    no_information_features_to_drop = ['all_util', 'dti_joint', 'il_util', 'inq_fi', 'inq_last_12m', 'max_bal_bc', 'mths_since_rcnt_il', 'open_acc_6m', 'open_il_12m', 'open_il_24m', 'open_il_6m', 'open_rv_12m', 'open_rv_24m', 'total_bal_il', 'verification_status_joint', 'annual_inc_joint', 'application_type',  'policy_code', 'total_cu_tl']\n",
    "    text_columns = ['emp_title', 'url', 'desc', 'purpose', 'title', 'zip_code', 'id']\n",
    "\n",
    "\n",
    "    no_leakage = no_incomplete_rows.drop(text_columns + leakage_to_drop + no_information_features_to_drop, axis = 1)\n",
    "\n",
    "    no_leakage['earliest_cr_line'] = pd.to_datetime(no_leakage['earliest_cr_line'], format='%b-%Y')\n",
    "    no_leakage['time_since_earliest_cr_line'] = no_leakage['earliest_cr_line'].apply(lambda x: pd.to_datetime('20000101', format='%Y%m%d') - x).dt.days\n",
    "\n",
    "    # and it looks like there's a pesky % symbol in my interest rate variable\n",
    "    no_leakage['int_rate'] = pd.to_numeric(no_leakage['int_rate'].str.strip('%'), errors='coerce')\n",
    "    no_leakage['revol_util'] = pd.to_numeric(no_leakage['revol_util'].str.strip('%'), errors='coerce')\n",
    "\n",
    "    no_leakage['term'] = no_leakage['term'].apply(lambda x: x.strip().replace(\" \", \"_\"))\n",
    "\n",
    "    no_leakage = no_leakage.drop(['earliest_cr_line'], axis = 1)\n",
    "    return(no_leakage)\n",
    "\n",
    "def data_pre_process(no_leakage):\n",
    "    categorical = no_leakage.select_dtypes(include=['object'])\n",
    "    numeric = no_leakage.select_dtypes(exclude=['object'])\n",
    "    \n",
    "    # create dummy variables\n",
    "    for name, values in categorical.items():\n",
    "        dummies = pd.get_dummies(values.str.strip(), prefix = name, dummy_na=True)\n",
    "        cleaned_data = pd.concat([numeric, dummies], axis=1)\n",
    "    return(cleaned_data)\n",
    "\n",
    "def data_Imputation(cleaned_data):\n",
    "    for name in cleaned_data:\n",
    "        if pd.isnull(cleaned_data[name]).sum() > 0:\n",
    "            cleaned_data[\"%s_mi\" % (name)] = pd.isnull(cleaned_data[name])\n",
    "            median = cleaned_data[name].median()\n",
    "            cleaned_data[name] = cleaned_data[name].apply(lambda x: median if pd.isnull(x) else x)\n",
    "    return(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 675 out of 675 | elapsed: 21.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardize', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=25, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))])\n",
      "0.684773303774\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the raw data from the csv file\n",
    "raw_data = get_lending_club_data()\n",
    "\n",
    "# Clean and process the data \n",
    "no_leakage = data_clean(raw_data)\n",
    "\n",
    "# Pre-process the data for modelling\n",
    "cleaned_data  = data_pre_process(no_leakage)\n",
    "\n",
    "# Imputation of missing values\n",
    "clean_imputed_data = data_Imputation(cleaned_data)\n",
    "\n",
    "#Defining Target and independent/predictor variables\n",
    "y = clean_imputed_data['loan_status']\n",
    "X = clean_imputed_data.drop(['loan_status'], axis = 1)\n",
    "\n",
    "#Creating the holdout\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "#Decision Tree model\n",
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "# set up cv\n",
    "from sklearn import model_selection\n",
    "cv = model_selection.KFold(5)\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps=[('standardize', preprocessing.StandardScaler()),('model', dt) ])\n",
    "\n",
    "\n",
    "# Parameters for tuning the model\n",
    "tree_depth = [5,6,7]\n",
    "tree_min_samples_split = [2, 10, 20]\n",
    "tree_min_samples_leaf = [1, 5, 10]\n",
    "tree_max_leaf_nodes = [10,20,25]\n",
    "#Implementing GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "optimized_dt = GridSearchCV(estimator=pipeline\n",
    "                            , cv=cv\n",
    "                            , param_grid=dict(model__max_depth= tree_depth, \n",
    "                                              model__min_samples_split = tree_min_samples_split,\n",
    "                                              model__min_samples_leaf = tree_min_samples_leaf,\n",
    "                                              model__max_leaf_nodes = tree_max_leaf_nodes)\n",
    "                            , scoring = 'roc_auc'\n",
    "                            , verbose = 1\n",
    "                            , n_jobs = -1)\n",
    "\n",
    "#Fitting the model with Grid Search\n",
    "optimized_dt.fit(X_train, y_train)\n",
    "\n",
    "#Get the best estimator from the grid Search\n",
    "print(optimized_dt.best_estimator_)\n",
    "print(optimized_dt.best_score_)\n",
    "\n",
    "# Evaluate on holdout\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = optimized_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_on_holdout = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(roc_on_holdout)\n",
    "\n",
    "# train model on entire dataset\n",
    "final = pipeline.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(dt, out_file='treepipe1.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier(max_depth=4,max_leaf_nodes=25, min_samples_leaf=10,min_samples_split=2)\n",
    "dt.fit(X,y)\n",
    "from sklearn.tree import export_graphviz\n",
    "dot_data=export_graphviz(dt,out_file=\"tree.dot\",feature_names=X.columns.values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
